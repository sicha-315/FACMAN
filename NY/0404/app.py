import eventlet
eventlet.monkey_patch()

import os
from flask import Flask, render_template, request, jsonify, send_file
from flask_socketio import SocketIO
from influxdb_client import InfluxDBClient
from dotenv import load_dotenv
from flask_cors import CORS
from docx import Document
from io import BytesIO
from docx.shared import Inches
import base64
import openai
from collections import defaultdict
from datetime import datetime, timezone, timedelta
import json
import traceback

# ===============================
# í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ===============================
load_dotenv()

app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode="eventlet")

INFLUX_URL = os.getenv("INFLUX_URL")
INFLUX_TOKEN = os.getenv("INFLUX_TOKEN")
INFLUX_ORG = os.getenv("INFLUX_ORG")
influx_client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
openai.api_key = os.getenv("OPENAI_API_KEY")

# ===============================
# í•œê¸€ ê¸°ê°„ ë¬¸ìì—´ ë³€í™˜ í•¨ìˆ˜
# ===============================
def normalize_range(range_str):
    kor_to_influx = {
        "1ì‹œê°„": "1h", "3ì‹œê°„": "3h", "6ì‹œê°„": "6h", "9ì‹œê°„": "9h",
        "1ì¼": "1d", "7ì¼": "7d", "31ì¼": "31d"
    }
    return kor_to_influx.get(range_str, range_str)

# ===============================
# ì‹¤ì‹œê°„ ìƒíƒœ ì¡°íšŒ ë° ì „ì†¡
# ===============================
def get_recent_status(bucket):
    query = f'''
    from(bucket: "{bucket}")
      |> range(start: -30s)
      |> filter(fn: (r) => r._measurement == "status_log" and r._field == "event_type")
      |> sort(columns: ["_time"], desc: true)
      |> limit(n: 3)
    '''
    result = influx_client.query_api().query(org=INFLUX_ORG, query=query)
    events = [record.get_value() for table in result for record in table.records]
    return events if events else None

def emit_status():
    prev_events = {"P1-A": None, "P1-B": None, "P2-A": None, "P2-B": None}
    while True:
        for key in prev_events.keys():
            events = get_recent_status(f"{key}_status")
            if events:
                latest = events[0]
                if latest != prev_events[key]:
                    socketio.emit('status_update', {key: {'event_type': latest}})
                    prev_events[key] = latest
        socketio.sleep(1)

@socketio.on('connect')
def handle_connect():
    for key in ["P1", "P2"]:
        events = get_recent_status(f"{key}_status")
        if events:
            latest = events[0]
            socketio.emit('status_update', {f"{key}-A": {'event_type': latest}})

# ===============================
# ë¼ìš°íŒ…
# ===============================
@app.route("/")
def index():
    return render_template("index.html")

@app.route("/report")
def report_page():
    return render_template("report.html")

# ===============================
# ë³´ê³ ì„œ ìƒì„± API (ë‹¤ì¤‘ ê³µì • ëŒ€ì‘)
# ===============================
@app.route("/generate_report", methods=["POST"])
def generate_report():
    try:
        data = request.get_json()
        processes = data.get("processes", [])
        range_str = normalize_range(data.get("range"))

        all_reports = []
        for process in processes:
            if "/" in range_str:
                start, end = range_str.split("/")
                range_clause = f'|> range(start: time(v: "{start}"), stop: time(v: "{end}"))'
                start_time = datetime.fromisoformat(start.replace("+09:00", ""))
                end_time = datetime.fromisoformat(end.replace("+09:00", ""))
            else:
                range_clause = f'|> range(start: -{range_str})'
                start_time, end_time = None, None

            query = f'''
            from(bucket: "{process}_status")
              {range_clause}
              |> filter(fn: (r) => r._measurement == "status_log")
              |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
              |> keep(columns: ["_time", "available", "event_type"])
            '''
            tables = influx_client.query_api().query(query)

            total, available_sum, failure_count = 0, 0, 0
            time_labels, available_values, failure_values = [], [], []
            failure_hourly = defaultdict(int)

            KST = timezone(timedelta(hours=9))

            for table in tables:
                for record in table.records:
                    event_type = record.get_value()
                    timestamp = record.get_time().astimezone(KST).replace(tzinfo=None)

                    # 1ï¸âƒ£ ê¸°ê°„ í•„í„°
                    if start and end:
                        if not (start <= timestamp <= end):
                            continue

                    # 2ï¸âƒ£ ìš´ì˜ ì‹œê°„ í•„í„° (09ì‹œ~18ì‹œ)
                    if not (9 <= timestamp.hour < 18):
                        continue

                    # 3ï¸âƒ£ ì´ë²¤íŠ¸ ì²˜ë¦¬
                    if event_type in ["failure", "maintenance"]:
                        current_event = event_type
                        current_start = timestamp

                    elif event_type == "processing" and current_event and current_start:
                        diff = (timestamp - current_start).total_seconds() / 60  # ë¶„ ë‹¨ìœ„
                        hour_label = current_start.strftime("%Hì‹œ")

                        if current_event == "failure":
                            failure_total += diff
                            failure_by_hour[hour_label] += diff
                        elif current_event == "maintenance":
                            maintenance_total += diff
                            maintenance_by_hour[hour_label] += diff

                        current_event = None
                        current_start = None

                    available = record.values.get("available", 0)
                    event_type = record.values.get("event_type", "")
                    timestamp = record_time.strftime("%H:%M")
                    hour_label = record_time.strftime("%Hì‹œëŒ€")

                    total += 1
                    available_sum += available
                    if event_type == "failure":
                        failure_count += 1
                        failure_hourly[hour_label] += 1

                    time_labels.append(timestamp)
                    available_values.append(round(available, 2))
                    failure_values.append(1 if event_type == "failure" else 0)

            avg_avail = round((available_sum / total) * 100, 1) if total else 0
            failure_table_labels = list(failure_hourly.keys())
            failure_table_counts = list(failure_hourly.values())

            prompt = f"""
            ê³µì •ëª…: {process}
            ê¸°ê°„: ìµœê·¼ {range_str}
            ê°€ë™ë¥  í‰ê· : {avg_avail}%
            ê³ ì¥ íšŸìˆ˜: {failure_count}íšŒ

            ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì¡° ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜. ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•´ì¤˜:
            1. ê³µì • ìš”ì•½
            2. ì£¼ìš” ì´ìŠˆ
            3. ëŒ€ì‘ ì¡°ì¹˜
            4. í–¥í›„ ì œì–¸
            """
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì œì¡°ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” AI ë¹„ì„œì•¼."},
                    {"role": "user", "content": prompt}
                ]
            )
            all_reports.append({
                "process": process,
                "report": response.choices[0].message.content,
                "labels": time_labels,
                "available": available_values,
                "failures": failure_values,
                "failureLabels": failure_table_labels,
                "failureCounts": failure_table_counts
            })

        return jsonify({"reports": all_reports})
    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# ===============================
# DOCX ë‹¤ìš´ë¡œë“œ API (ì‹œê°„ëŒ€ ê·¸ë£¹í•‘ ë°˜ì˜)
# ===============================
from flask import request

@app.route("/generate_docx", methods=["POST"])
def generate_docx():
    try:
        text = request.form.get("report", "")
        failure_labels = request.form.get("failureLabels", "[]")
        failure_counts = request.form.get("failureCounts", "[]")

        doc = Document()
        doc.add_heading("ğŸ“„ ìŠ¤ë§ˆíŠ¸ ì œì¡° ë³´ê³ ì„œ", 0)
        doc.add_paragraph(text)

        # âœ… ì´ë¯¸ì§€ ì¶”ê°€
        avail_imgs = request.files.getlist("availabilityImages")
        fail_imgs = request.files.getlist("failureImages")

        for i in range(len(avail_imgs)):
            doc.add_paragraph(f"âœ… [{i+1}] ê°€ë™ë¥  ë³€í™”")
            doc.add_picture(BytesIO(avail_imgs[i].read()), width=Inches(4))

        for i in range(len(fail_imgs)):
            doc.add_paragraph(f"ğŸ“Š [{i+1}] ê³ ì¥ ë°œìƒ ë¶„í¬")
            doc.add_picture(BytesIO(fail_imgs[i].read()), width=Inches(4))

        # âœ… ê³ ì¥ í…Œì´ë¸”
        import json
        labels = json.loads(failure_labels)
        counts = json.loads(failure_counts)

        hour_map = {}
        for label, count in zip(labels, counts):
            hour = label[:2] + "ì‹œëŒ€"
            hour_map[hour] = hour_map.get(hour, 0) + count

        doc.add_paragraph("ğŸ“Š ê³ ì¥ ë°œìƒ ë¶„í¬ í…Œì´ë¸” (ì‹œê°„ëŒ€ ê¸°ì¤€)")
        table = doc.add_table(rows=1, cols=2)
        hdr_cells = table.rows[0].cells
        hdr_cells[0].text = 'ì‹œê°„ëŒ€'
        hdr_cells[1].text = 'ê³ ì¥ ìˆ˜'
        for hour, count in hour_map.items():
            row_cells = table.add_row().cells
            row_cells[0].text = hour
            row_cells[1].text = str(count)

        output = BytesIO()
        doc.save(output)
        output.seek(0)
        return send_file(output, as_attachment=True, download_name="ì œì¡°_ë³´ê³ ì„œ.docx")
    except Exception as e:
        print(f"ğŸ“„ DOCX ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"error": "íŒŒì¼ ìƒì„± ì‹¤íŒ¨"}), 500


# ===============================
# ë‹¤ìš´íƒ€ì„ ê³„ì‚° API
# ===============================
@app.route("/get_downtime_data", methods=["POST"])
def get_downtime_data():
    from datetime import datetime, timezone, timedelta
    from collections import defaultdict

    data = request.json
    process = data.get("process")
    range_str = data.get("range")

    if not process or not range_str:
        return jsonify({"error": "Missing process or range"}), 400

    # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
    if "/" in range_str:
        start_str, end_str = range_str.split("/")
        start = datetime.fromisoformat(start_str.replace("Z", "").replace("+09:00", ""))
        end = datetime.fromisoformat(end_str.replace("Z", "").replace("+09:00", ""))
        range_clause = f'|> range(start: time(v: "{start_str}"), stop: time(v: "{end_str}"))'
    else:
        range_clause = f'|> range(start: -{range_str})'
        now = datetime.utcnow()
        if "h" in range_str:
            hours = int(range_str.replace("h", ""))
            start = now - timedelta(hours=hours)
        elif "d" in range_str:
            days = int(range_str.replace("d", ""))
            start = now - timedelta(days=days)
        end = now

    query = f'''
    from(bucket: "{process}_status")
      {range_clause}
      |> filter(fn: (r) => r._measurement == "status_log" and r._field == "event_type")
      |> sort(columns: ["_time"])
    '''

    tables = influx_client.query_api().query(org=INFLUX_ORG, query=query)

    # ë‹¤ìš´íƒ€ì„ ëˆ„ì 
    failure_total = 0
    maintenance_total = 0
    failure_by_hour = defaultdict(int)
    maintenance_by_hour = defaultdict(int)

    current_event = None
    current_start = None

    KST = timezone(timedelta(hours=9))

    for table in tables:
        for record in table.records:
            event_type = record.get_value()
            timestamp = record.get_time().astimezone(KST).replace(tzinfo=None)

            if event_type in ["failure", "maintenance"]:
                current_event = event_type
                current_start = timestamp
            elif event_type == "processing" and current_event and current_start:
                diff = (timestamp - current_start).total_seconds() / 60  # ë¶„ ë‹¨ìœ„
                hour_label = current_start.strftime("%Hì‹œ")

                if current_event == "failure":
                    failure_total += diff
                    failure_by_hour[hour_label] += diff
                elif current_event == "maintenance":
                    maintenance_total += diff
                    maintenance_by_hour[hour_label] += diff

                current_event = None
                current_start = None

    return jsonify({
        "failure_total": round(failure_total, 1),
        "maintenance_total": round(maintenance_total, 1),
        "hourly_labels": sorted(set(list(failure_by_hour.keys()) + list(maintenance_by_hour.keys()))),
        "failure_by_hour": [round(failure_by_hour[h], 1) for h in sorted(failure_by_hour.keys())],
        "maintenance_by_hour": [round(maintenance_by_hour[h], 1) for h in sorted(maintenance_by_hour.keys())]
    })


# ===============================
# ê°€ë™ë¥  ê³„ì‚° API
# ===============================
@app.route("/calculate_availability", methods=["POST"])
def calculate_availability():
    try:
        data = request.json
        process = data.get("process")  # ì˜ˆì‹œ: "P1-A"
        period = data.get("period")    # "ì¼ê°„", "ì£¼ê°„", "ì›”ê°„"

        # ê¸°ê°„ ì„¤ì •
        now = datetime.utcnow()
        if period == "ì¼ê°„":
            start = now - timedelta(hours=24)
        elif period == "ì£¼ê°„":
            start = now - timedelta(days=7)
        elif period == "ì›”ê°„":
            start = now - timedelta(days=31)
        else:
            return jsonify({"error": "Invalid period"}), 400

        start_str = start.isoformat() + "Z"
        end_str = now.isoformat() + "Z"

        # ì¿¼ë¦¬ë¬¸
        query = f'''
        from(bucket: "{process}_status")
          |> range(start: {start_str}, stop: {end_str})
          |> filter(fn: (r) => r._measurement == "status_log" and r._field == "available")
        '''

        tables = influx_client.query_api().query(org=INFLUX_ORG, query=query)

        # ë°ì´í„° ìˆ˜ì§‘ ë° ê³„ì‚°
        total, available_sum = 0, 0
        for table in tables:
            for record in table.records:
                timestamp = record.get_time().astimezone(KST).replace(tzinfo=None)
                hour = timestamp.hour

                # âœ… ìš´ì˜ ì‹œê°„ í•„í„°: 09ì‹œ ~ 18ì‹œë§Œ í¬í•¨
                if not (9 <= hour < 18):
                    continue

                value = record.get_value()
                if value is not None:
                    total += 1
                    available_sum += value

        availability = round((available_sum / total) * 100, 1) if total else 0

        return jsonify({
            "process": process,
            "period": period,
            "availability": availability
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ===============================
# ê³ ì¥ê±´ìˆ˜ API ì¶”ê°€
# ===============================
@app.route("/calculate_failure_count", methods=["POST"])
def calculate_failure_count():
    try:
        data = request.json
        process = data.get("process")  # ì˜ˆ: "P1-A"
        period = data.get("period")    # "ì¼ê°„", "ì£¼ê°„", "ì›”ê°„"

        # ê¸°ê°„ ì„¤ì •
        now = datetime.utcnow()
        if period == "ì¼ê°„":
            start = now - timedelta(hours=24)
        elif period == "ì£¼ê°„":
            start = now - timedelta(days=7)
        elif period == "ì›”ê°„":
            start = now - timedelta(days=31)
        else:
            return jsonify({"error": "Invalid period"}), 400

        start_str = start.isoformat() + "Z"
        end_str = now.isoformat() + "Z"

        # ì¿¼ë¦¬ë¬¸
        query = f'''
        from(bucket: "{process}_status")
        |> range(start: {start_str}, stop: {end_str})
        |> filter(fn: (r) => r._measurement == "status_log" and r._field == "event_type" and r._value == "failure")
        '''

        tables = influx_client.query_api().query(org=INFLUX_ORG, query=query)

        KST = timezone(timedelta(hours=9))
        failure_count = 0

        for table in tables:
            for record in table.records:
                timestamp = record.get_time().astimezone(KST).replace(tzinfo=None)
                hour = timestamp.hour

                # âœ… ìš´ì˜ ì‹œê°„ë§Œ í¬í•¨
                if not (9 <= hour < 18):
                    continue

                failure_count += 1

        return jsonify({
            "process": process,
            "period": period,
            "failure_count": failure_count
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ===============================
# ì„œë²„ ì‹¤í–‰
# ===============================
if __name__ == "__main__":
    socketio.start_background_task(target=emit_status)
    socketio.run(app, host='0.0.0.0', port=5000, debug=False, use_reloader=False)

