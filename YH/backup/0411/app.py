import eventlet
eventlet.monkey_patch()

import os
import base64
from io import BytesIO
from flask import Flask, render_template, request, jsonify, send_file
from flask_socketio import SocketIO
from influxdb_client import InfluxDBClient
from openai import OpenAI
from dotenv import load_dotenv
from flask_cors import CORS
from docx import Document
from docx.shared import Inches
from datetime import datetime

from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langchain.agents import Tool
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableConfig
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… Flask ì•± ë° SocketIO ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode="eventlet")

# âœ… InfluxDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
INFLUX_URL = os.getenv("INFLUX_URL")
INFLUX_TOKEN = os.getenv("INFLUX_TOKEN")
INFLUX_ORG = os.getenv("INFLUX_ORG")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

influx_client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# âœ… ìƒíƒœ emit í•¨ìˆ˜
def emit_status():
    print("[DEBUG] emit_status() ì‹¤í–‰ ì‹œì‘")
    prev_events = {
        "P1-A": None,
        "P1-B": None,
        "P2-A": None,
        "P2-B": None
    }

    while True:
        for bucket, label in [
            ("P1-A_status", "P1-A"),
            ("P1-B_status", "P1-B"),
            ("P2-A_status", "P2-A"),
            ("P2-B_status", "P2-B")
        ]:
            events = get_recent_status(bucket)
            if events:
                latest = events[0]
                if latest != prev_events[label]:
                    print(f"[Influx] {label} ìƒíƒœ ë³€ê²½: {latest}")
                    socketio.emit('status_update', {
                        label: {'event_type': latest}
                    })
                    prev_events[label] = latest
        socketio.sleep(1)

# âœ… ë©”ì¸ í˜ì´ì§€ ë¼ìš°íŒ… ì¶”ê°€
def index():
    return render_template("index.html")
app.route("/")(index)

# âœ… ìœ ìš©ì„± í˜ì´ì§€ ë¼ìš°íŒ… ì¶”ê°€
def usefulness():
    return render_template("usefulness.html")
app.route("/usefulness")(usefulness)

# âœ… ìƒì‚° ì¶”ì´ ë°ì´í„° API ì¶”ê°€
def floor_to_hour(dt):
    return dt.replace(minute=0, second=0, microsecond=0)

@app.route("/get_production_data", methods=["POST"])
def get_production_data():
    try:
        # ğŸ” ì‹¤ì œ ìƒì‚° ì™„ë£Œë§Œ ì¹´ìš´íŠ¸ (status == "finish")
        query = '''
        from(bucket: "process")
        |> range(start: -12h)
        |> filter(fn: (r) => r._measurement == "process_log" and r._field == "status" and r._value == "finish")
        |> group(columns:["line_id"])
        |> aggregateWindow(every: 1h, fn: count, createEmpty: false)
        '''
        result = influx_client.query_api().query(org=INFLUX_ORG, query=query)

        # ê¸°ì¤€ ì‹œê°„ëŒ€ ì •ì˜ (09:00 ~ 18:00)
        time_slots = [f"{h:02}:00" for h in range(9, 19)]
        label_set = set(time_slots)
        data_by_line = {line: {} for line in ["P1-A", "P1-B", "P2-A", "P2-B"]}

        for table in result:
            for record in table.records:
                time_label = record.get_time().strftime("%H:%M")
                line_id = record.values.get("line_id")
                value = int(record.get_value())
                if line_id in data_by_line and time_label in label_set:
                    data_by_line[line_id][time_label] = value

        response = {"labels": time_slots}
        for line_id in data_by_line:
            response[line_id] = [data_by_line[line_id].get(t, 0) for t in time_slots]

        return jsonify(response)

    except Exception as e:
        return jsonify({"error": str(e)}), 500


# âœ… ì±—ë´‡/Langgraph ì„¤ì •
class State(TypedDict):
    messages: Annotated[list, add_messages]

# âœ… InfluxDB ì¿¼ë¦¬ìš© Tool í•¨ìˆ˜
def influxdb_flux_query_tool(process_id: str):
    query_api = influx_client.query_api()

    if not process_id or not isinstance(process_id, str):
        return "ì˜¬ë°”ë¥¸ process_id ë˜ëŠ” line_idë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: 'P1' ë˜ëŠ” 'P1-A')"

    if "-" in process_id:
        query = f'''
        from(bucket: "process")
        |> range(start: -12h)
        |> filter(fn: (r) => r._measurement == "process_log")
        |> filter(fn: (r) => r.line_id == "{process_id}")
        '''
    else:
        query = f'''
        from(bucket: "process")
        |> range(start: -12h)
        |> filter(fn: (r) => r._measurement == "process_log")
        |> filter(fn: (r) => r.process_id == "{process_id}")
        '''

    try:
        tables = query_api.query(query)
        logs = []
        for table in tables:
            for record in table.records:
                logs.append(f"{record.get_time()}: {record.get_value()}")
        return "\n".join(logs) if logs else f"{process_id}ì— ëŒ€í•œ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# âœ… LangGraph ì±—ë´‡ ìƒì„± í•¨ìˆ˜
def create_langgraph_chatbot():
    tools = [Tool(
        name="query_process_logs",
        func=influxdb_flux_query_tool,
        description="Inputì€ 'P1' ë˜ëŠ” 'P1-A'ì™€ ê°™ì€ process_idë‚˜ line_idì…ë‹ˆë‹¤."
    )]

    system_prompt = (
        "ë„ˆëŠ” ì œì¡° ê³µì • ë°ì´í„°ë¥¼ í•´ì„í•´ì£¼ëŠ” ì „ë¬¸ ì±—ë´‡ì´ì•¼.\n"
        "ğŸ“Œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ **í•­ìƒ ë‹¨ í•˜ë‚˜ì˜ ëª…í™•í•œ ë¬¸ì¥**ìœ¼ë¡œ ìš”ì•½ëœ ë‹µë³€ì„ ì œê³µí•´.\n"
        "ì˜ˆ: 'ìµœê·¼ 1ì‹œê°„ ë™ì•ˆ P2-Aì˜ í‰ê·  ê°€ë™ë¥ ì€ 74.3%ì…ë‹ˆë‹¤.'\n"
        "\n"
        "âœ… ë°˜ë“œì‹œ ì•„ë˜ ê¸°ì¤€ì„ ì§€ì¼œ:\n"
        "- ê³„ì‚° ê³¼ì •ì´ë‚˜ ë¡œê·¸ ë°ì´í„°ë¥¼ ì„¤ëª…í•˜ê±°ë‚˜ ë‚˜ì—´í•˜ì§€ ë§ˆ.\n"
        "- ìˆ˜ì‹, í‘œ, ì½”ë“œ ë¸”ë¡ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.\n"
        "- '~ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:', '~ì…ë‹ˆë‹¤:', '~ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:' ê°™ì€ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆ.\n"
        "- ë‹µë³€ ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë§ˆì¹¨í‘œë¡œ ëë‚´ê³ , ë§ì¤„ì„í‘œ(...) ì‚¬ìš©í•˜ì§€ ë§ˆ.\n"
        "- ë¦¬ìŠ¤íŠ¸ë¥¼ ë‚˜ì—´í•  ë• ê¼­ ì¤„ë°”ê¿ˆí•´ì„œ í‘œì‹œí•´.\n"
        "- ë‹¨ìœ„(%, íšŒ ë“±)ëŠ” ìƒëµí•˜ì§€ ë§ê³  ë°˜ë“œì‹œ í‘œì‹œí•´.\n"
        "- ì¤‘ë³µë˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ í‘œí˜„ì€ ì¤„ì´ê³ , ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ ë§í•´.\n"
        "\n"
        "â›” ì•„ë˜ëŠ” ê¸ˆì§€ëœ í‘œí˜„ ì˜ˆì‹œì•¼:\n"
        "- ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: ... (ê¸ˆì§€)\n"
        "- ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”. (ê¸ˆì§€)\n"
        "- 90%ì˜ ê°€ë™ë¥ ì…ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. (ê°ì‚¬ëŠ” ê¸ˆì§€)\n"
        "\n"
        "ğŸ§  ë„ˆì˜ ì—­í• ì€ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼, ë°ì´í„°ë¥¼ í•´ì„í•´ì„œ ì •í™•í•œ ë¬¸ì¥ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì´ì•¼.\n"
        "ë§ˆì§€ë§‰ìœ¼ë¡œ, **ë°˜ë“œì‹œ ìµœì†Œ í•˜ë‚˜ì˜ 'ì •í™•í•œ ìˆ˜ì¹˜'ë¥¼ í¬í•¨**í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´."
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder("messages"),
    ])

    llm = ChatOpenAI(model="gpt-4o", temperature=0).bind_tools(tools)
    chain = prompt | llm

    def chatbot_node(state: State):
        return {"messages": [chain.invoke(state["messages"])]}

    graph = StateGraph(State)
    graph.add_node("chatbot", chatbot_node)
    graph.add_node("tools", ToolNode(tools=tools))
    graph.add_conditional_edges("chatbot", tools_condition)
    graph.add_edge("tools", "chatbot")
    graph.set_entry_point("chatbot")
    graph.set_finish_point("chatbot")
    
    return graph.compile(checkpointer=MemorySaver())

# âœ… /chat ë¼ìš°íŒ…: LangGraph ê¸°ë°˜ ì±—ë´‡
@app.route("/chat", methods=["POST"])
def chat():
    user_message = request.json.get("message", "")
    try:
        graph = create_langgraph_chatbot()
        config = RunnableConfig(recursion_limit=10, configurable={"thread_id": "web-user"})
        response_text = ""
        for event in graph.stream({"messages": [{"role": "user", "content": user_message}]}, config=config):
            for value in event.values():
                if "messages" in value and value["messages"]:
                    response_text = value["messages"][-1].content
        return jsonify({"reply": response_text})
    except Exception as e:
        return jsonify({"reply": f"âŒ LangGraph ì±—ë´‡ ì˜¤ë¥˜: {str(e)}"}), 500


# âœ… ìµœê·¼ ì´ë²¤íŠ¸ ìƒíƒœ ì¡°íšŒ í•¨ìˆ˜
def get_recent_status(bucket):
    query = f'''
    from(bucket: "{bucket}")
      |> range(start: -30s)
      |> filter(fn: (r) => r._measurement == "status_log" and r._field == "event_type")
      |> sort(columns: ["_time"], desc: true)
      |> limit(n: 3)
    '''
    result = influx_client.query_api().query(org=INFLUX_ORG, query=query)

    events = []
    for table in result:
        for record in table.records:
            events.append(record.get_value())
    return events if events else None

# âœ… í´ë¼ì´ì–¸íŠ¸ ìµœì´ˆ ì—°ê²° ì‹œ ìƒíƒœ ì „ì†¡
@socketio.on('connect')
def handle_connect():
    print('Client connected')
    for bucket, label in [
        ("P1-A_status", "P1-A"),
        ("P1-B_status", "P1-B"),
        ("P2-A_status", "P2-A"),
        ("P2-B_status", "P2-B")
    ]:
        events = get_recent_status(bucket)
        if events:
            latest = events[0]
            socketio.emit('status_update', {
                label: {'event_type': latest}
            })


# âœ… ë³´ê³ ì„œ í˜ì´ì§€
@app.route("/report")
def report_page():
    return render_template("report.html")

# âœ… ë³´ê³ ì„œ ìƒì„± API
@app.route("/generate_report", methods=["POST"])
def generate_report():
    data = request.json
    process = data.get("process")
    range_str = data.get("range")
    query = f'''
    from(bucket: "{process}_status")
      |> range(start: -{range_str})
      |> filter(fn: (r) => r._measurement == "status_log")
      |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
      |> keep(columns: ["_time", "available", "event_type"])
    '''
    tables = influx_client.query_api().query(query)
    total = 0
    available_sum = 0
    failure_count = 0
    time_labels = []
    available_values = []
    failure_values = []
    for table in tables:
        for record in table.records:
            available = record.values.get("available", 0)
            event_type = record.values.get("event_type", "")
            timestamp = record.values["_time"].strftime("%H:%M")
            total += 1
            available_sum += available
            if event_type == "failure":
                failure_count += 1
            time_labels.append(timestamp)
            available_values.append(round(available, 2))
            failure_values.append(1 if event_type == "failure" else 0)
    avg_avail = round((available_sum / total) * 100, 1) if total else 0
    prompt = f"""
ê³µì •ëª…: {process}
ê¸°ê°„: ìµœê·¼ {range_str}
ê°€ë™ë¥  í‰ê· : {avg_avail}%
ê³ ì¥ íšŸìˆ˜: {failure_count}íšŒ

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì¡° ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜. ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•´ì¤˜:
1. ê³µì • ìš”ì•½
2. ì£¼ìš” ì´ìŠˆ
3. ëŒ€ì‘ ì¡°ì¹˜
4. í–¥í›„ ì œì–¸
"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì œì¡°ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” AI ë¹„ì„œì•¼."},
                {"role": "user", "content": prompt}
            ]
        )
        return jsonify({
            "report": response.choices[0].message.content,
            "labels": time_labels,
            "available": available_values,
            "failures": failure_values
        })
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"error": str(e)}), 500

# âœ… ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ API
@app.route("/generate_docx", methods=["POST"])
def generate_docx():
    try:
        data = request.json
        text = data.get("report", "")
        avail_img_b64 = data.get("availabilityImage", "")
        fail_img_b64 = data.get("failureImage", "")
        doc = Document()
        doc.add_heading("\ud83d\udcc4 ìŠ¤ë§ˆíŠ¸ ì œì¡° ë³´ê³ ì„œ", 0)
        doc.add_paragraph(text)
        def add_image(doc, b64_string, title):
            if b64_string and "base64," in b64_string:
                try:
                    doc.add_paragraph(title)
                    image_data = base64.b64decode(b64_string.split(",")[-1])
                    image_stream = BytesIO(image_data)
                    doc.add_picture(image_stream, width=Inches(2.75))
                except Exception as img_err:
                    print(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {img_err}")
        add_image(doc, avail_img_b64, "\u2705 ê°€ë™ë¥  ë³€í™”")
        add_image(doc, fail_img_b64, "\ud83d\udcca ê³ ì¥ ë°œìƒ ë¶„í¬")
        output = BytesIO()
        doc.save(output)
        output.seek(0)
        return send_file(output, as_attachment=True, download_name="ì œì¡°_ë³´ê³ ì„œ.docx")
    except Exception as e:
        print(f"\ud83d\udd1b DOCX ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"error": "íŒŒì¼ ìƒì„± ì‹¤íŒ¨"}), 500


# âœ… ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    socketio.start_background_task(target=emit_status)
    socketio.run(app, host='0.0.0.0', port=5000, debug=False, use_reloader=False, log_output=True)