import eventlet
eventlet.monkey_patch()

import os
import base64
from io import BytesIO
from flask import Flask, render_template, request, jsonify, send_file
from flask_socketio import SocketIO
from influxdb_client import InfluxDBClient
from dotenv import load_dotenv
from flask_cors import CORS
from docx import Document
from docx.shared import Inches

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… Flask ì•± ë° SocketIO ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode="eventlet")

# âœ… InfluxDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
INFLUX_URL = os.getenv("INFLUX_URL")
INFLUX_TOKEN = os.getenv("INFLUX_TOKEN")
INFLUX_ORG = os.getenv("INFLUX_ORG")
influx_client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)

# âœ… ìƒíƒœ emit í•¨ìˆ˜
def emit_status():
    print("[DEBUG] emit_status() ì‹¤í–‰ ì‹œì‘")
    prev_events = {
        "P1-A": None,
        "P1-B": None,
        "P2-A": None,
        "P2-B": None
    }

    while True:
        for bucket, label in [
            ("P1-A_status", "P1-A"),
            ("P1-B_status", "P1-B"),
            ("P2-A_status", "P2-A"),
            ("P2-B_status", "P2-B")
        ]:
            events = get_recent_status(bucket)
            if events:
                latest = events[0]
                if latest != prev_events[label]:
                    print(f"[Influx] {label} ìƒíƒœ ë³€ê²½: {latest}")
                    socketio.emit('status_update', {
                        label: {'event_type': latest}
                    })
                    prev_events[label] = latest
        socketio.sleep(1)


# âœ… ë©”ì¸ í˜ì´ì§€ ë¼ìš°íŒ… ì¶”ê°€
def index():
    return render_template("index.html")
app.route("/")(index)

# âœ… ìœ ìš©ì„± í˜ì´ì§€ ë¼ìš°íŒ… ì¶”ê°€
def usefulness():
    return render_template("usefulness.html")
app.route("/usefulness")(usefulness)

# âœ¨ âœ… ìœ ìš©ì„± ë°ì´í„° API ë¼ìš°íŒ… ì¶”ê°€
@app.route("/get_usefulness_data", methods=["POST"])
def get_usefulness_data():
    try:
        data = request.get_json()
        process = data.get("process", "P1-A")
        time_range = data.get("range", "6h")

        # ì˜ˆì‹œ Flux ì½”ë“œëŠ” í‰ê·  available ê³„ì‚°ì„ ê°€ì§€ê³  ì˜¬ ìˆ˜ ìˆì–´ìš”
        query = f'''
        from(bucket: "{process}_status")
          |> range(start: -{time_range})
          |> filter(fn: (r) => r._measurement == "status_log" and r._field == "available")
          |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)
          |> yield(name: "mean")
        '''

        result = influx_client.query_api().query(org=INFLUX_ORG, query=query)
        labels, values = [], []
        for table in result:
            for record in table.records:
                labels.append(record.get_time().strftime("%H:%M"))
                values.append(round(record.get_value() * 100, 1))  # í„€ì‹œí‹°ì§€

        return jsonify({
            "labels": labels,
            "values": values
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# âœ… ìµœê·¼ ì´ë²¤íŠ¸ ìƒíƒœ ì¡°íšŒ í•¨ìˆ˜
def get_recent_status(bucket):
    query = f'''
    from(bucket: "{bucket}")
      |> range(start: -30s)
      |> filter(fn: (r) => r._measurement == "status_log" and r._field == "event_type")
      |> sort(columns: ["_time"], desc: true)
      |> limit(n: 3)
    '''
    result = influx_client.query_api().query(org=INFLUX_ORG, query=query)

    events = []
    for table in result:
        for record in table.records:
            events.append(record.get_value())
    return events if events else None


# âœ… í´ë¼ì´ì–¸íŠ¸ ìµœì´ˆ ì—°ê²° ì‹œ ìƒíƒœ ì „ì†¡
@socketio.on('connect')
def handle_connect():
    print('Client connected')
    for bucket, label in [
        ("P1-A_status", "P1-A"),
        ("P1-B_status", "P1-B"),
        ("P2-A_status", "P2-A"),
        ("P2-B_status", "P2-B")
    ]:
        events = get_recent_status(bucket)
        if events:
            latest = events[0]
            socketio.emit('status_update', {
                label: {'event_type': latest}
            })

# âœ… ë³´ê³ ì„œ í˜ì´ì§€
@app.route("/report")
def report_page():
    return render_template("report.html")

# âœ… ë³´ê³ ì„œ ìƒì„± API
@app.route("/generate_report", methods=["POST"])
def generate_report():
    data = request.json
    process = data.get("process")
    range_str = data.get("range")
    query = f'''
    from(bucket: "{process}_status")
      |> range(start: -{range_str})
      |> filter(fn: (r) => r._measurement == "status_log")
      |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
      |> keep(columns: ["_time", "available", "event_type"])
    '''
    tables = influx_client.query_api().query(query)
    total = 0
    available_sum = 0
    failure_count = 0
    time_labels = []
    available_values = []
    failure_values = []
    for table in tables:
        for record in table.records:
            available = record.values.get("available", 0)
            event_type = record.values.get("event_type", "")
            timestamp = record.values["_time"].strftime("%H:%M")
            total += 1
            available_sum += available
            if event_type == "failure":
                failure_count += 1
            time_labels.append(timestamp)
            available_values.append(round(available, 2))
            failure_values.append(1 if event_type == "failure" else 0)
    avg_avail = round((available_sum / total) * 100, 1) if total else 0
    prompt = f"""
ê³µì •ëª…: {process}
ê¸°ê°„: ìµœê·¼ {range_str}
ê°€ë™ë¥  í‰ê· : {avg_avail}%
ê³ ì¥ íšŸìˆ˜: {failure_count}íšŒ

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì¡° ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜. ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•´ì¤˜:
1. ê³µì • ìš”ì•½
2. ì£¼ìš” ì´ìŠˆ
3. ëŒ€ì‘ ì¡°ì¹˜
4. í–¥í›„ ì œì–¸
"""
    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì œì¡°ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” AI ë¹„ì„œì•¼."},
                {"role": "user", "content": prompt}
            ]
        )
        return jsonify({
            "report": response.choices[0].message.content,
            "labels": time_labels,
            "available": available_values,
            "failures": failure_values
        })
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"error": str(e)}), 500

# âœ… ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ API
@app.route("/generate_docx", methods=["POST"])
def generate_docx():
    try:
        data = request.json
        text = data.get("report", "")
        avail_img_b64 = data.get("availabilityImage", "")
        fail_img_b64 = data.get("failureImage", "")
        doc = Document()
        doc.add_heading("\ud83d\udcc4 ìŠ¤ë§ˆíŠ¸ ì œì¡° ë³´ê³ ì„œ", 0)
        doc.add_paragraph(text)
        def add_image(doc, b64_string, title):
            if b64_string and "base64," in b64_string:
                try:
                    doc.add_paragraph(title)
                    image_data = base64.b64decode(b64_string.split(",")[-1])
                    image_stream = BytesIO(image_data)
                    doc.add_picture(image_stream, width=Inches(2.75))
                except Exception as img_err:
                    print(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {img_err}")
        add_image(doc, avail_img_b64, "\u2705 ê°€ë™ë¥  ë³€í™”")
        add_image(doc, fail_img_b64, "\ud83d\udcca ê³ ì¥ ë°œìƒ ë¶„í¬")
        output = BytesIO()
        doc.save(output)
        output.seek(0)
        return send_file(output, as_attachment=True, download_name="ì œì¡°_ë³´ê³ ì„œ.docx")
    except Exception as e:
        print(f"\ud83d\udd1b DOCX ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"error": "íŒŒì¼ ìƒì„± ì‹¤íŒ¨"}), 500

@app.route("/chat", methods=["POST"])
def chat():
    user_message = request.json.get("message", "")
    intent_prompt = f"""
ë„ˆëŠ” AI ì—ì´ì „íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì¤˜.
- influx: ì œì¡° ê³µì •ì´ë‚˜ ì„¤ë¹„ ìƒíƒœ, ê³ ì¥ ë“± InfluxDBì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•˜ëŠ” ì§ˆë¬¸
- web: ì™¸ë¶€ ë‰´ìŠ¤, ì‹œì„¸, ì¼ë°˜ ì •ë³´ ë“± ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
- gpt: ì¼ë°˜ì ì¸ ì§€ì‹ì´ë‚˜ ê°œë… ì„¤ëª…, ì¡ë‹´ ë“±

ì§ˆë¬¸: "{user_message}"
ìœ„ ì§ˆë¬¸ì€ ì–´ë–¤ ìœ í˜•ì´ì•¼? ë°˜ë“œì‹œ influx / web / gpt ì¤‘ í•˜ë‚˜ë§Œ ë§í•´ì¤˜.
"""
    try:
        intent_res = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ intentë¥¼ ë¶„ì„í•˜ëŠ” íŒë‹¨ ì—ì´ì „íŠ¸ì•¼."},
                {"role": "user", "content": intent_prompt}
            ]
        )
        intent_raw = intent_res.choices[0].message.content.strip().lower()
        intent = intent_raw if intent_raw in ["influx", "web", "gpt"] else "gpt"
        if intent == "influx":
            reply = handle_influx_query(user_message)
        elif intent == "web":
            reply = "\ud83d\udd0d ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì€ í˜„ì¬ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."
        else:
            reply = handle_gpt_query(user_message)
        return jsonify({"reply": reply})
    except Exception as e:
        return jsonify({"reply": f"\u26a0\ufe0f ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500

# âœ… GPT ì²˜ë¦¬ í•¨ìˆ˜
def handle_gpt_query(user_message):
    gpt_reply = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ì œì¡° ê³µì • AI ë¹„ì„œì•¼."},
            {"role": "user", "content": user_message}
        ]
    )
    return gpt_reply.choices[0].message.content.strip()

# âœ… Influx ì²˜ë¦¬ í•¨ìˆ˜ (GPT ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„± + ì‹¤í–‰)
def handle_influx_query(user_message):
    query_prompt = f"""
ë„ˆëŠ” InfluxDB ì „ë¬¸ê°€ì•¼. ë‹¤ìŒê³¼ ê°™ì´ ì •í™•í•˜ê²Œ Flux ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì¤˜.

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ë²„í‚· ì´ë¦„ì€ ë°˜ë“œì‹œ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ê³ ì •í•´ì•¼ í•´:
  - "P1-A_status"
  - "P1-B_status"
  - "P2-A_status"
  - "P2-B_status"
- "your_bucket" ê°™ì€ í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ë©´ ì•ˆ ë¼.
- ì¿¼ë¦¬ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœì—¬ì•¼ í•˜ê³ , ê²°ê³¼ì— _value ë˜ëŠ” available, event_type í•„ë“œê°€ ìˆì–´ì•¼ í•´.

ì‚¬ìš©ì ì§ˆë¬¸: "{user_message}"
Flux ì¿¼ë¦¬ë§Œ ë°˜í™˜í•´ì¤˜. ì„¤ëª…ì€ í•„ìš” ì—†ì–´.
"""
    try:
        gpt_query_res = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” InfluxDB ì¿¼ë¦¬ ìƒì„± ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": query_prompt}
            ]
        )
        flux_query = gpt_query_res.choices[0].message.content.strip()
        print("âœ… ìƒì„±ëœ ì¿¼ë¦¬:\n", flux_query)
        result_tables = influx_client.query_api().query(flux_query)
        result_rows = []
        for table in result_tables:
            for record in table.records:
                values = record.values
                time_str = str(values.get("_time", "(ì‹œê°„ ì—†ìŒ)"))
                field_str = str(values.get("_field", "(í•„ë“œ ì—†ìŒ)"))
                value_str = str(values.get("_value", values.get("value", "(ê°’ ì—†ìŒ)")))
                result_rows.append(f"{time_str} - {field_str} = {value_str}")
        if not result_rows:
            return "ğŸ“ InfluxDBì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return "ğŸ“Š InfluxDB ì‘ë‹µ ê²°ê³¼:\n" + "\n".join(result_rows[:10])
    except Exception as e:
        return f"âš ï¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# âœ… ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    socketio.start_background_task(target=emit_status)
    socketio.run(app, host='0.0.0.0', port=5000, debug=False, use_reloader=False, log_output=True)