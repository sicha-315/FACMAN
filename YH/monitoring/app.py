from flask import Flask, request, jsonify, render_template, send_file
from flask_socketio import SocketIO, emit
from influxdb_client import InfluxDBClient
from docx import Document
from docx.shared import Inches
from io import BytesIO
from openai import OpenAI
import base64
from threading import Thread
from time import sleep
import os
from dotenv import load_dotenv

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
socketio = SocketIO(app)  # âœ… SocketIO í™œì„±í™”

# âœ… .envì—ì„œ ë¯¼ê° ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
INFLUX_URL = os.getenv("INFLUX_URL")
INFLUX_TOKEN = os.getenv("INFLUX_TOKEN")
INFLUX_ORG = os.getenv("INFLUX_ORG")

influx_client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)

# âœ… ë©”ì¸ ëŒ€ì‹œë³´ë“œ í˜ì´ì§€
@app.route("/")
def index():
    return render_template("index.html")

# âœ… ê³µì • ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ê°ì§€í•˜ê³  WebSocketìœ¼ë¡œ ì „ì†¡
def emit_status_loop():
    while True:
        try:
            statuses = {}

            for process in ["P1", "P2"]:
                try:
                    query = f'''
                    from(bucket: "{process}_status")
                      |> range(start: -5m)
                      |> filter(fn: (r) => r._measurement == "status_log" and r._field == "available")
                      |> last()
                    '''

                    print(f"ğŸ” {process} ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")

                    tables = influx_client.query_api().query(query)
                    found = False

                    for table in tables:
                        for record in table.records:
                            value = record.get_value()
                            print(f"âœ… {process} ìƒíƒœê°’:", value)
                            statuses[process] = int(value)
                            found = True

                    if not found:
                        print(f"âš ï¸ {process}: ìµœê·¼ 5ë¶„ ë‚´ 'available' ë°ì´í„° ì—†ìŒ")

                except Exception as e:
                    print(f"âŒ {process} ì¿¼ë¦¬ ì˜¤ë¥˜:", e)

            print("ğŸ“¤ emití•  ìƒíƒœ:", statuses)
            socketio.emit('status_update', statuses)

        except Exception as e:
            print("ğŸ”¥ ìƒíƒœ ì†¡ì‹  ì˜¤ë¥˜:", e)

        sleep(5)


# âœ… ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹¤í–‰
@socketio.on('connect')
def handle_connect():
    print("ğŸ“¡ í´ë¼ì´ì–¸íŠ¸ WebSocket ì—°ê²°ë¨")


# âœ… ë³´ê³ ì„œ í˜ì´ì§€
@app.route("/report")
def report_page():
    return render_template("report.html")

# âœ… ë³´ê³ ì„œ ìƒì„± API
@app.route("/generate_report", methods=["POST"])
def generate_report():
    data = request.json
    process = data.get("process")
    range_str = data.get("range")

    query = f'''
    from(bucket: "{process}_status")
      |> range(start: -{range_str})
      |> filter(fn: (r) => r._measurement == "status_log")
      |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
      |> keep(columns: ["_time", "available", "event_type"])
    '''

    tables = influx_client.query_api().query(query)

    total = 0
    available_sum = 0
    failure_count = 0
    time_labels = []
    available_values = []
    failure_values = []

    for table in tables:
        for record in table.records:
            available = record.values.get("available", 0)
            event_type = record.values.get("event_type", "")
            timestamp = record.values["_time"].strftime("%H:%M")

            total += 1
            available_sum += available
            if event_type == "failure":
                failure_count += 1

            time_labels.append(timestamp)
            available_values.append(round(available, 2))
            failure_values.append(1 if event_type == "failure" else 0)

    avg_avail = round((available_sum / total) * 100, 1) if total else 0

    prompt = f"""
ê³µì •ëª…: {process}
ê¸°ê°„: ìµœê·¼ {range_str}
ê°€ë™ë¥  í‰ê· : {avg_avail}%
ê³ ì¥ íšŸìˆ˜: {failure_count}íšŒ

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì¡° ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜. ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•´ì¤˜:
1. ê³µì • ìš”ì•½
2. ì£¼ìš” ì´ìŠˆ
3. ëŒ€ì‘ ì¡°ì¹˜
4. í–¥í›„ ì œì–¸
"""

    try:
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì œì¡°ê³µì • ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” AI ë¹„ì„œì•¼."},
                {"role": "user", "content": prompt}
            ]
        )
        return jsonify({
            "report": response.choices[0].message.content,
            "labels": time_labels,
            "available": available_values,
            "failures": failure_values
        })
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({"error": str(e)}), 500

# âœ… ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ API
@app.route("/generate_docx", methods=["POST"])
def generate_docx():
    try:
        data = request.json
        text = data.get("report", "")
        avail_img_b64 = data.get("availabilityImage", "")
        fail_img_b64 = data.get("failureImage", "")

        doc = Document()
        doc.add_heading("ğŸ“„ ìŠ¤ë§ˆíŠ¸ ì œì¡° ë³´ê³ ì„œ", 0)
        doc.add_paragraph(text)

        def add_image(doc, b64_string, title):
            if b64_string and "base64," in b64_string:
                try:
                    doc.add_paragraph(title)
                    image_data = base64.b64decode(b64_string.split(",")[-1])
                    image_stream = BytesIO(image_data)
                    doc.add_picture(image_stream, width=Inches(2.75))
                except Exception as img_err:
                    print(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {img_err}")

        add_image(doc, avail_img_b64, "âœ… ê°€ë™ë¥  ë³€í™”")
        add_image(doc, fail_img_b64, "ğŸ“Š ê³ ì¥ ë°œìƒ ë¶„í¬")

        output = BytesIO()
        doc.save(output)
        output.seek(0)
        return send_file(output, as_attachment=True, download_name="ì œì¡°_ë³´ê³ ì„œ.docx")

    except Exception as e:
        print(f"ğŸ“› DOCX ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"error": "íŒŒì¼ ìƒì„± ì‹¤íŒ¨"}), 500


@app.route("/chat", methods=["POST"])
def chat():
    user_message = request.json.get("message", "")

    # âœ… 1ë‹¨ê³„: intent ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
    intent_prompt = f"""
ë„ˆëŠ” AI ì—ì´ì „íŠ¸ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì¤˜.
- influx: ì œì¡° ê³µì •ì´ë‚˜ ì„¤ë¹„ ìƒíƒœ, ê³ ì¥ ë“± InfluxDBì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•˜ëŠ” ì§ˆë¬¸
- web: ì™¸ë¶€ ë‰´ìŠ¤, ì‹œì„¸, ì¼ë°˜ ì •ë³´ ë“± ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
- gpt: ì¼ë°˜ì ì¸ ì§€ì‹ì´ë‚˜ ê°œë… ì„¤ëª…, ì¡ë‹´ ë“±

ì§ˆë¬¸: "{user_message}"
ìœ„ ì§ˆë¬¸ì€ ì–´ë–¤ ìœ í˜•ì´ì•¼? ë°˜ë“œì‹œ influx / web / gpt ì¤‘ í•˜ë‚˜ë§Œ ë§í•´ì¤˜.
"""

    try:
        intent_res = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ intentë¥¼ ë¶„ì„í•˜ëŠ” íŒë‹¨ ì—ì´ì „íŠ¸ì•¼."},
                {"role": "user", "content": intent_prompt}
            ]
        )
        intent_raw = intent_res.choices[0].message.content.strip().lower()
        intent = intent_raw if intent_raw in ["influx", "web", "gpt"] else "gpt"

        # âœ… 2ë‹¨ê³„: intentì— ë”°ë¼ ì²˜ë¦¬
        if intent == "influx":
            reply = handle_influx_query(user_message)
        elif intent == "web":
            reply = "ğŸ” ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì€ í˜„ì¬ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤."
        else:
            reply = handle_gpt_query(user_message)

        return jsonify({"reply": reply})
    except Exception as e:
        return jsonify({"reply": f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}), 500


# âœ… GPT ì²˜ë¦¬ í•¨ìˆ˜
def handle_gpt_query(user_message):
    gpt_reply = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ì œì¡° ê³µì • AI ë¹„ì„œì•¼."},
            {"role": "user", "content": user_message}
        ]
    )
    return gpt_reply.choices[0].message.content.strip()


# âœ… Influx ì²˜ë¦¬ í•¨ìˆ˜ (GPT ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„± + ì‹¤í–‰)
def handle_influx_query(user_message):
    # Step 1: ì‚¬ìš©ì ì§ˆë¬¸ì„ Flux ì¿¼ë¦¬ë¡œ ë³€í™˜ (ë²„í‚·ëª… ê³ ì • ì•ˆë‚´ í¬í•¨)
    query_prompt = f"""
ë„ˆëŠ” InfluxDB ì „ë¬¸ê°€ì•¼. ë‹¤ìŒê³¼ ê°™ì´ ì •í™•í•˜ê²Œ Flux ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì¤˜.

âš ï¸ ì£¼ì˜ì‚¬í•­:
- ë²„í‚· ì´ë¦„ì€ ë°˜ë“œì‹œ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ê³ ì •í•´ì•¼ í•´:
  - "P1_status"
  - "P2_status"
- "your_bucket" ê°™ì€ í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ë©´ ì•ˆ ë¼.
- ì¿¼ë¦¬ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœì—¬ì•¼ í•˜ê³ , ê²°ê³¼ì— _value ë˜ëŠ” available, event_type í•„ë“œê°€ ìˆì–´ì•¼ í•´.

ì‚¬ìš©ì ì§ˆë¬¸: "{user_message}"
Flux ì¿¼ë¦¬ë§Œ ë°˜í™˜í•´ì¤˜. ì„¤ëª…ì€ í•„ìš” ì—†ì–´.
"""

    try:
        gpt_query_res = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” InfluxDB ì¿¼ë¦¬ ìƒì„± ì „ë¬¸ê°€ì•¼."},
                {"role": "user", "content": query_prompt}
            ]
        )
        flux_query = gpt_query_res.choices[0].message.content.strip()
        print("âœ… ìƒì„±ëœ ì¿¼ë¦¬:\n", flux_query)

        # Step 2: InfluxDB ì¿¼ë¦¬ ì‹¤í–‰
        result_tables = influx_client.query_api().query(flux_query)

        # Step 3: ê²°ê³¼ íŒŒì‹±
        result_rows = []
        for table in result_tables:
            for record in table.records:
                values = record.values
                time_str = str(values.get("_time", "(ì‹œê°„ ì—†ìŒ)"))
                field_str = str(values.get("_field", "(í•„ë“œ ì—†ìŒ)"))
                value_str = str(values.get("_value", values.get("value", "(ê°’ ì—†ìŒ)")))

                result_rows.append(f"{time_str} - {field_str} = {value_str}")

        if not result_rows:
            return "ğŸ“­ InfluxDBì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return "ğŸ“Š InfluxDB ì‘ë‹µ ê²°ê³¼:\n" + "\n".join(result_rows[:10])

    except Exception as e:
        return f"âš ï¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# âœ… ì•± ì‹¤í–‰
if __name__ == "__main__":
    Thread(target=emit_status_loop, daemon=True).start()  # âœ… ìƒíƒœ ê°ì§€ ìŠ¤ë ˆë“œ ì‹œì‘
    socketio.run(app, debug=True, host="0.0.0.0", port=5000)
